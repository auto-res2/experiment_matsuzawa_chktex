Warning 1 in paper.tex line 89: Command terminated with space.
  \State initialize environment $\mathcal{E}$ and model parameters $\theta$  
        ^
Warning 1 in paper.tex line 91: Command terminated with space.
    \State reset $\mathcal{E}$ to obtain initial state $s_0$  
          ^
Warning 1 in paper.tex line 93: Command terminated with space.
      \State aggregate recent state sequence $\{s_{t-L},\dots,s_t\}$  
            ^
Warning 1 in paper.tex line 94: Command terminated with space.
      \State $h_t \gets \textsc{TransformerEncoder}(\{s_{t-L},\dots,s_t\};\theta)$  
            ^
Warning 1 in paper.tex line 95: Command terminated with space.
      \State sample action $a_t \sim \pi_\theta(\cdot\mid h_t)$  
            ^
Warning 1 in paper.tex line 96: Command terminated with space.
      \State execute $a_t$ in $\mathcal{E}$, observe $s_{t+1}$, reward $r_t$  
            ^
Warning 1 in paper.tex line 97: Command terminated with space.
      \State store transition $(s_t,a_t,r_t,s_{t+1})$ in buffer  
            ^
Warning 1 in paper.tex line 98: Command terminated with space.
    \EndWhile  
             ^
Warning 1 in paper.tex line 99: Command terminated with space.
    \State compute returns $G_t$ for stored trajectory  
          ^
Warning 1 in paper.tex line 100: Command terminated with space.
    \State update $\theta \leftarrow \theta + \alpha \nabla_\theta \mathbb{E}[G_t\,\log \pi_\theta(a_t\mid h_t)]$  
          ^
Warning 1 in paper.tex line 102: Command terminated with space.
      \State evaluate current policy over fixed set of episodes  
            ^
Warning 1 in paper.tex line 103: Command terminated with space.
    \EndIf  
          ^
Warning 1 in paper.tex line 104: Command terminated with space.
  \EndFor  
         ^
